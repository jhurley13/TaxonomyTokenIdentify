{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxonomic Token Identify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "\n",
    "See https://medium.com/@jhurley_97842/create-a-template-for-your-jupyter-notebooks-80352d265cd4 for how the notebook was created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import re\n",
    "import json\n",
    "import more_itertools\n",
    "import requests\n",
    "import urllib\n",
    "import ftfy\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter-specific Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 30\n",
    "\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "\n",
    "# autoreload extension\n",
    "if 'autoreload' not in ipython.extension_manager.loaded:\n",
    "    get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "\n",
    "get_ipython().run_line_magic('autoreload', '2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@rrfd/cookiecutter-data-science-organize-your-projects-atom-and-jupyter-2be7862f487e\n",
    "# Base Path\n",
    "base_path = Path.cwd()\n",
    "\n",
    "# Data paths\n",
    "data_path = base_path / 'data'\n",
    "raw_data_path = data_path / 'raw'\n",
    "interim_data_path = data_path / 'interim'\n",
    "processed_data_path = data_path / 'processed'\n",
    "external_data_path = data_path / 'external'\n",
    "\n",
    "# Reports paths\n",
    "reports_path = base_path / 'reports'\n",
    "figures_path = reports_path / 'figures'\n",
    "\n",
    "# Input paths\n",
    "taxonomy_name = 'eBird-Clements-v2019-integrated-checklist-August-2019.xlsx'\n",
    "taxonomy_path = external_data_path / taxonomy_name\n",
    "\n",
    "test_data_path = raw_data_path / 'raw-spacytest-small.txt'\n",
    "\n",
    "# Cache paths\n",
    "entity_ruler_path = interim_data_path / 'taxon_entity_ruler.jsonl'\n",
    "\n",
    "# Outputs paths\n",
    "\n",
    "# Credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and Globals\n",
    "# Just for readability\n",
    "ua_p1 = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) '\n",
    "ua_p2 = 'AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15'\n",
    "REQUESTS_USER_AGENT = ua_p1 + ua_p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_project_paths():\n",
    "    default_mode = 0o755\n",
    "    data_path.mkdir(mode=default_mode, parents=False, exist_ok=True)\n",
    "    raw_data_path.mkdir(mode=default_mode, parents=False, exist_ok=True)\n",
    "    interim_data_path.mkdir(mode=default_mode, parents=False, exist_ok=True)\n",
    "    processed_data_path.mkdir(mode=default_mode, parents=False, exist_ok=True)\n",
    "    external_data_path.mkdir(mode=default_mode, parents=False, exist_ok=True)\n",
    "    reports_path.mkdir(mode=default_mode, parents=False, exist_ok=True)\n",
    "    figures_path.mkdir(mode=default_mode, parents=False, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxonomy_from_url(url):\n",
    "    taxonomy_path = external_data_path / taxonomy_name\n",
    "\n",
    "    try:\n",
    "        xheaders={'User-Agent': REQUESTS_USER_AGENT}\n",
    "\n",
    "        rr = requests.get(url, params=None, headers=xheaders, stream=True)\n",
    "\n",
    "        if rr.status_code == requests.codes.ok:\n",
    "            with open(taxonomy_path, 'wb') as fp:\n",
    "                _ = fp.write(rr.content)\n",
    "        rr.raise_for_status()\n",
    "\n",
    "    except Exception as ee:\n",
    "        print(ee)\n",
    "\n",
    "    return rr.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxonomy_cached() -> pd.DataFrame:\n",
    "    taxonomy_df = pd.DataFrame()\n",
    "    try:\n",
    "        if not taxonomy_path.is_file():\n",
    "            url_base = 'https://www.birds.cornell.edu/clementschecklist/wp-content/uploads/2019/08'\n",
    "            url = f'{url_base}/{taxonomy_name}'\n",
    "            print(f'Retrieving taxonomy for cache...')\n",
    "            get_taxonomy_from_url(url)\n",
    "            \n",
    "        if taxonomy_path.is_file():\n",
    "            taxonomy_df = pd.read_excel(taxonomy_path, header=0).fillna('')\n",
    "            new_tax_columns = {\n",
    "                'English name': 'comName',\n",
    "                'scientific name': 'sciName',\n",
    "                'family': 'familySciName',\n",
    "                'eBird species group': 'familyComName'\n",
    "            }\n",
    "            taxonomy_df.rename(columns=new_tax_columns, inplace=True)\n",
    "\n",
    "    except Exception as ee:\n",
    "        print(ee)\n",
    "        pass\n",
    "\n",
    "    return taxonomy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_text(test_path: Path) -> str:\n",
    "    print(f'Processing {test_path.stem}')\n",
    "    with open(test_path, 'r', encoding=\"utf-8\") as fp:\n",
    "        text = fp.read()\n",
    "\n",
    "    # Generally helpful to clean up the text at least a little bit\n",
    "    text = ftfy.fix_text(text, fix_encoding=True, fix_line_breaks=True,\n",
    "                         normalization='NFKC',\n",
    "                         fix_latin_ligatures=True, uncurl_quotes=True)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_visualization(test_path: Path, html:str):\n",
    "    # Pass in original filename\n",
    "    out_path = reports_path / f'spacy-{test_path.stem}.html'\n",
    "    with open(out_path, 'w', encoding=\"utf-8\") as fp: #, encoding=\"utf-8\"\n",
    "        _ = fp.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_taxon_patterns(nlp, values:pd.Series, label:str, taxon_patterns:list):\n",
    "    values = list(set(values.values))\n",
    "    if '' in values:\n",
    "        values.remove('')\n",
    "    for val in values:\n",
    "        # use word_tokenize to properly group \"'s\"\n",
    "        tokens = nlp.tokenizer(val)\n",
    "        patterns = [{'LOWER': str(tok).lower()} for tok in tokens]\n",
    "        taxon_pattern = {'label': label, 'pattern': patterns}\n",
    "        taxon_patterns.append(taxon_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_taxon_patterns(nlp, taxonomy):\n",
    "    print('Preparing taxon patterns')\n",
    "\n",
    "    taxon_patterns = []\n",
    "    \n",
    "    create_taxon_patterns(nlp, taxonomy.comName, 'CommonName', taxon_patterns)\n",
    "    create_taxon_patterns(nlp, taxonomy.sciName, 'ScientificName', taxon_patterns)\n",
    "    create_taxon_patterns(nlp, taxonomy.order, 'Order', taxon_patterns)\n",
    "    create_taxon_patterns(nlp, taxonomy.familyComName, 'FamilyCommon', taxon_patterns)\n",
    "    create_taxon_patterns(nlp, taxonomy.familySciName, 'FamilyScientific', taxon_patterns)\n",
    "    \n",
    "    return taxon_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_ruler_cached(nlp, taxonomy) -> EntityRuler:\n",
    "    ruler = EntityRuler(nlp, validate=True)\n",
    "    try:\n",
    "        if not entity_ruler_path.is_file():\n",
    "            taxon_patterns = add_taxon_patterns(nlp, taxonomy)\n",
    "            ruler.add_patterns(taxon_patterns)\n",
    "            ruler.to_disk(entity_ruler_path)\n",
    "            return ruler\n",
    "        \n",
    "        if entity_ruler_path.is_file():\n",
    "            print('Loading EntityRuler from cache...')\n",
    "            ruler.from_disk(entity_ruler_path)\n",
    "\n",
    "    except Exception as ee:\n",
    "        print(ee)\n",
    "        pass\n",
    "\n",
    "    return ruler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and process text\n",
    "def spacify_text(text, taxonomy):\n",
    "    # Only process unique lines\n",
    "    processed_text = '\\n'.join(list(set(text.split('\\n'))))\n",
    "\n",
    "    nlp = English()\n",
    "\n",
    "    ruler = get_entity_ruler_cached(nlp, taxonomy)\n",
    "    nlp.add_pipe(ruler)\n",
    "\n",
    "    print('Processing text')\n",
    "    doc = nlp(processed_text.lower())\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visualization(docx, show_in_jupyter=True):\n",
    "    # Create visualization\n",
    "    # https://developer.mozilla.org/en-US/docs/Web/CSS/linear-gradient\n",
    "    # https://cssgradient.io\n",
    "    # https://htmlcolorcodes.com\n",
    "    \n",
    "    print('Creating visualization')\n",
    "    \n",
    "    purplish   = 'linear-gradient(90deg, #aa9cfc, #fc9ce7)' # original\n",
    "    yellowish  = 'linear-gradient(90deg, #f9fc9c, #fac945)'\n",
    "    greenish   = 'linear-gradient(90deg, #cdfc9c, #5cfa45)'\n",
    "    aquaish    = 'linear-gradient(90deg, #9cfcea, #3cd3e7)'\n",
    "    fuchsiaish = 'linear-gradient(90deg, #fc9cde, #ff5aa4)'\n",
    "\n",
    "    colors = {\n",
    "        \"COMMONNAME\": purplish,\n",
    "        'SCIENTIFICNAME': aquaish,\n",
    "        'ORDER': greenish,\n",
    "        'FAMILYCOMMON': yellowish,\n",
    "        'FAMILYSCIENTIFIC': fuchsiaish\n",
    "    }\n",
    "    options = {\"ents\": [\"COMMONNAME\", 'SCIENTIFICNAME', 'ORDER', \n",
    "                        'FAMILYCOMMON', 'FAMILYSCIENTIFIC'], \n",
    "               \"colors\": colors}\n",
    "\n",
    "    # displacy.serve(doc, style=\"ent\", options=options)\n",
    "    html = displacy.render([docx], style=\"ent\", page=True, \n",
    "                           jupyter=show_in_jupyter, options=options)\n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_species_and_families(docx):\n",
    "    families = set()\n",
    "    species = set()\n",
    "    for ent in docx.ents:\n",
    "        if ent.label_ == 'FamilyCommon':\n",
    "            families.add(ent.text)\n",
    "        elif ent.label_ == 'CommonName':\n",
    "            species.add(ent.text)\n",
    "    #     print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "    xspecies = ', '.join(sorted(list(species)))\n",
    "    xfamilies = ', '.join(sorted(list(families)))\n",
    "\n",
    "    print(f'Species: {xspecies}')\n",
    "    print(f'Families: {xfamilies}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializations\n",
    "\n",
    "taxonomy = get_taxonomy_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other files to try\n",
    "#     test_data_path = processed_data_path / 'raw-spacytest-small-article.txt'\n",
    "#     test_data_path = processed_data_path / 'the-119th-christmas-bird-count-summary.txt'\n",
    "#     test_data_path = processed_data_path / 'raw-pdf-txt-1-cl-CACR-CMHCBC_-_Check_List2018.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    create_project_paths()\n",
    "    \n",
    "    test_data_path = processed_data_path / 'raw-spacytest-small.txt'\n",
    "    text = get_test_text(test_data_path)\n",
    "    \n",
    "    docx = spacify_text(text, taxonomy)\n",
    "    show_species_and_families(docx)\n",
    "    \n",
    "    html = create_visualization(docx, show_in_jupyter=True)\n",
    "\n",
    "    html = create_visualization(docx, show_in_jupyter=False)\n",
    "    save_visualization(test_data_path, html)\n",
    "    \n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
